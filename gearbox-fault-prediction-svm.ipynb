{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Will be shuffling the final aggregated dataset before using in the model as the data values are sequential. Shuffled dataset will be divided into training and testing. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom matplotlib import pyplot\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import shuffle\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Healthy Datas**","metadata":{}},{"cell_type":"markdown","source":"Below are all the sensor readings of healthy gears from loading conditions 0% to 90%.  ","metadata":{}},{"cell_type":"code","source":"h30hz0  = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz0.csv\")\nh30hz10 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz10.csv\")\nh30hz20 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz20.csv\")\nh30hz30 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz30.csv\")\nh30hz40 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz40.csv\")\nh30hz50 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz50.csv\")\nh30hz60 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz60.csv\")\nh30hz70 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz70.csv\")\nh30hz80 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz80.csv\")\nh30hz90 = pd.read_csv(\"../input/gearbox-fault-diagnosis/Healthy/h30hz90.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Broken Datas**","metadata":{}},{"cell_type":"markdown","source":"Below are all the sensor readings of broken gears from loading conditions 0% to 90%.  ","metadata":{}},{"cell_type":"code","source":"b30hz0  = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz0.csv\")\nb30hz10 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz10.csv\")\nb30hz20 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz20.csv\")\nb30hz30 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz30.csv\")\nb30hz40 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz40.csv\")\nb30hz50 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz50.csv\")\nb30hz60 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz60.csv\")\nb30hz70 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz70.csv\")\nb30hz80 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz80.csv\")\nb30hz90 = pd.read_csv(\"../input/gearbox-fault-diagnosis/BrokenTooth/b30hz90.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Headview of a healthy gear reading from 0% loading","metadata":{}},{"cell_type":"code","source":"h30hz0.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add Load and Failure Column for Healthy\n\n### 0 --> Healhty\n### 1 --> Broken","metadata":{}},{"cell_type":"code","source":"failure = 0\n\nload = 0\n\nh30hz0['load'] = load*np.ones((len(h30hz0.index),1))\nfailureArray = np.zeros((len(h30hz0.index),1))\nh30hz0['failure'] = failureArray\n\nload = 10\n\nh30hz10['load'] = load*np.ones((len(h30hz10.index),1))\nfailureArray = np.zeros((len(h30hz10.index),1))\nh30hz10['failure'] = failureArray\n\nload = 20\n\nh30hz20['load'] = load*np.ones((len(h30hz20.index),1))\nfailureArray = np.zeros((len(h30hz20.index),1))\nh30hz20['failure'] = failureArray\n\nload = 30\n\nh30hz30['load'] = load*np.ones((len(h30hz30.index),1))\nfailureArray = np.zeros((len(h30hz30.index),1))\nh30hz30['failure'] = failureArray\n\nload = 40\n\nh30hz40['load'] = load*np.ones((len(h30hz40.index),1))\nfailureArray = np.zeros((len(h30hz40.index),1))\nh30hz40['failure'] = failureArray\n\nload = 50\n\nh30hz50['load'] = load*np.ones((len(h30hz50.index),1))\nfailureArray = np.zeros((len(h30hz50.index),1))\nh30hz50['failure'] = failureArray\n\nload = 60\n\nh30hz60['load'] = load*np.ones((len(h30hz60.index),1))\nfailureArray = np.zeros((len(h30hz60.index),1))\nh30hz60['failure'] = failureArray\n\nload = 70\n\nh30hz70['load'] = load*np.ones((len(h30hz70.index),1))\nfailureArray = np.zeros((len(h30hz70.index),1))\nh30hz70['failure'] = failureArray\n\nload = 80\n\nh30hz80['load'] = load*np.ones((len(h30hz80.index),1))\nfailureArray = np.zeros((len(h30hz80.index),1))\nh30hz80['failure'] = failureArray\n\nload = 90\n\nh30hz90['load'] = load*np.ones((len(h30hz90.index),1))\nfailureArray = np.zeros((len(h30hz90.index),1))\nh30hz90['failure'] = failureArray","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the new data table with load and healthy condition added","metadata":{}},{"cell_type":"code","source":"h30hz90.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add Load and Failure Column for Broken","metadata":{}},{"cell_type":"code","source":"failure = 1\n\nload = 0\n\nb30hz0['load'] = load*np.ones((len(b30hz0.index),1))\nfailureArray = np.ones((len(b30hz0.index),1))\nb30hz0['failure'] = failureArray\n\nload = 10 \n\nb30hz10['load'] = load*np.ones((len(b30hz10.index),1))\nfailureArray = np.ones((len(b30hz10.index),1))\nb30hz10['failure'] = failureArray\n\nload = 20 \n\nb30hz20['load'] = load*np.ones((len(b30hz20.index),1))\nfailureArray = np.ones((len(b30hz20.index),1))\nb30hz20['failure'] = failureArray\n\nload = 30 \n\nb30hz30['load'] = load*np.ones((len(b30hz30.index),1))\nfailureArray = np.ones((len(b30hz30.index),1))\nb30hz30['failure'] = failureArray\n\nload = 40 \n\nb30hz40['load'] = load*np.ones((len(b30hz40.index),1))\nfailureArray = np.ones((len(b30hz40.index),1))\nb30hz40['failure'] = failureArray\n\nload = 50 \n\nb30hz50['load'] = load*np.ones((len(b30hz50.index),1))\nfailureArray = np.ones((len(b30hz50.index),1))\nb30hz50['failure'] = failureArray\n\nload = 60 \n\nb30hz60['load'] = load*np.ones((len(b30hz60.index),1))\nfailureArray = np.ones((len(b30hz60.index),1))\nb30hz60['failure'] = failureArray\n\nload = 70 \n\nb30hz70['load'] = load*np.ones((len(b30hz70.index),1))\nfailureArray = np.ones((len(b30hz70.index),1))\nb30hz70['failure'] = failureArray\n\nload = 80 \n\nb30hz80['load'] = load*np.ones((len(b30hz80.index),1))\nfailureArray = np.ones((len(b30hz80.index),1))\nb30hz80['failure'] = failureArray\n\nload = 90 \n\nb30hz90['load'] = load*np.ones((len(b30hz90.index),1))\nfailureArray = np.ones((len(b30hz90.index),1))\nb30hz90['failure'] = failureArray","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the new data table with load and broken condition added","metadata":{}},{"cell_type":"code","source":"# check\nb30hz90.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Concat Healty and Broken","metadata":{}},{"cell_type":"code","source":"# Broken \n\nbroken_df = pd.concat([b30hz0,b30hz10,b30hz20,b30hz30,b30hz40,b30hz50,b30hz60,b30hz70,b30hz80,b30hz90],axis=0,ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Healthy\n\nhealthy_df = pd.concat([h30hz0,h30hz10,h30hz20,h30hz30,h30hz40,h30hz50,h30hz60,h30hz70,h30hz80,h30hz90],axis=0,ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check \nhealthy_df.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check \nbroken_df.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gear_data   = pd.concat([broken_df,healthy_df], axis =0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the final aggregated dataset","metadata":{}},{"cell_type":"code","source":"gear_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gear_data.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling SVM","metadata":{}},{"cell_type":"code","source":"training_features = ['a1', 'a2', 'a3', 'a4', 'load']\nlabel = ['failure']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = gear_data[training_features]\nx.shape #training features of consists of 2021119 rows and 5 columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = gear_data[label]\ny.shape #label data consists of 2021119 rows and 1 col ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y = shuffle(x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1=x.head(60000)\ny1=y.head(60000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1,y1 = shuffle(x1,y1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1_train.shape,x1_test.shape, y1_train.shape, y1_test.shape ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = svm.SVC(kernel='rbf', gamma='auto', C=1.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.fit(x1_train, y1_train.values.ravel())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = classifier.predict(x1_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating classification report","metadata":{}},{"cell_type":"code","source":"print(classification_report(y1_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(accuracy_score(y1_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}